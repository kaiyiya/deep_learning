幻灯片第1页：标题页
大家好，今天我要给大家介绍一种叫"纠正式检索增强生成"，也就是CRAG的新方法。这其实是一个很轻量的解决方案，主要目的就是让大语言模型在生成内容时更准确、更可靠。接下来我会从研究背景开始，到方法设计，再到实验验证，给大家全面讲解一下CRAG到底有什么价值。

幻灯片第2页：研究背景与核心挑战
现在的大语言模型，也就是LLM（Large Language Model，大语言模型），在生成质量和推理能力上确实很厉害，但是有两个大问题一直困扰着大家：
第一个是LLM本身的问题：它经常会出现"幻觉"，什么是幻觉呢？就是模型会生成一些看起来很有道理，但实际上并不准确的信息，就像人会产生错误的记忆一样；而且这些事实性错误很难预测和控制；另外，它的知识更新速度也跟不上现实世界的变化，因为它训练时的知识是固定的。
第二个是RAG的问题：RAG全称是检索增强生成（Retrieval-Augmented Generation），简单说就是先从数据库里找相关资料，再用这些资料来生成答案。虽然这种方法能改善一些知识任务的表现，但它对检索质量特别敏感，一旦检索结果不好，整个系统就崩了，而且它也没有机制来判断检索结果到底靠不靠谱。这些问题直接影响了LLM在实际应用中能不能用。

幻灯片第3页：问题定义
那么CRAG到底要解决什么问题呢？简单来说，就是给定一个输入x（比如用户的问题）和一个语料库C（就是存放文档的数据库），检索器R会返回top-K个文档集合D（也就是最相关的K个文档），然后生成器G基于输入x和检索文档D来生成输出y（也就是最终的答案）。
关键问题来了：如果检索到的文档D质量不行，论文怎么才能让生成的概率P(y|x)更鲁棒、更准确呢？这里解释一下，鲁棒性就是系统在面对错误输入时仍然能保持稳定工作的能力。这就是CRAG要解决的核心问题。

幻灯片第4页：CRAG方法概览
CRAG是一个插件式的、轻量化的校正机制，可以很方便地集成到现有的RAG系统里。插件式就是说，它不需要改变整个系统架构，就像给手机装个APP一样简单。它主要通过三个步骤来提升生成质量：智能评估（就是判断检索结果好不好）、动态决策（根据评估结果选择不同的处理方式）和知识精炼（把有用的信息提取出来，去掉没用的）。接下来我会详细给大家拆解一下它的核心创新点。


幻灯片第5页：CRAG核心创新
CRAG主要有四大核心创新：
第一个是检索评估器：用一个轻量级的评估器来给检索结果打分，看看它到底有多相关、有多可信。这个评估器就像是一个质检员，专门负责检查检索到的文档质量；
第二个是置信度判断：根据评分把结果分成三种状态，Correct就是可信的（可以放心用），Incorrect就是不可信的（不能直接用），Ambiguous就是有点模糊的（部分可用）。置信度就是系统对自己判断的信心程度；
第三个是动态策略：根据不同的置信度，系统会采取不同的处理策略。比如可信的就直接用，不可信的就去找外部资源；
第四个是知识精炼：通过分解再重组的机制，把那些噪音过滤掉，只提取高质量的知识片段。噪音就是那些无关的、干扰的信息。
这四大创新加在一起，就构成了CRAG的鲁棒性基础。


幻灯片第6页：检索评估器设计
检索评估器是干什么的呢？它的核心功能就是给每个查询和文档的配对计算一个细粒度的相关性分数。细粒度就是非常详细、精确的意思。它有什么特点呢？
首先，它用的是轻量级模型，所以计算开销不会太大，不会让系统变慢太多；
其次，它可以通过微调来适配不同的领域。微调就是在一个已经训练好的模型基础上，用特定领域的数据再训练一下，让它更懂这个领域；
然后，它输出的是连续分数，这样论文可以更灵活地做决策。连续分数就是像0.85、0.92这样的小数，而不是只有好或坏两种选择；
最后，它既能评估整个文档，也能评估段落级别的内容，这样就更精确了。
有了这个评估器，论文就不用盲目相信检索结果了，可以为后续的决策提供可靠的依据。


幻灯片第7页：三级置信度判断机制
CRAG通过一个三级置信度判断机制来动态调整策略。动态调整就是根据实际情况随时改变处理方式，而不是死板地用同一种方法：
如果是CORRECT，说明检索结果总体上是可信的，那就只做内部的知识精炼就够了。内部精炼就是从已经检索到的文档里提取有用的信息；
如果是INCORRECT，说明检索结果不可信，那就得触发外部Web搜索去找更准确的信息。外部搜索就是去网上找，比如用Google搜索；
如果是AMBIGUOUS，就是部分可信，那就内部精炼和外部检索都做，这样更保险。
这种分类机制让系统能在不同场景下都能灵活应对。


幻灯片第8页：知识精炼：分解-重组策略
知识精炼用的是分解再重组的策略，主要分三步：
第一步是文档分段：把检索到的文档切成一个个独立的知识片段，也就是strips。就像把一篇文章分成一段一段的；
第二步是评分过滤：用评估器给每个片段打分，只保留得分最高的Top-k个段落。Top-k就是保留得分最高的k个，比如Top-5就是保留前5名；
第三步是有序重组：按照原文的顺序，把筛选出来的段落重新组合起来。这样能保持原文的逻辑顺序，不会打乱。
这个机制能有效剔除那些干扰信息，大大提高上下文的相关性。上下文相关性就是生成的内容和问题之间的关联程度。


幻灯片第9页：外部Web搜索增强

当内部的检索不够用的时候，CRAG会启动外部搜索来补充：
它先用GPT-3.5 Turbo生成一些精简的搜索关键词。GPT-3.5 Turbo是OpenAI开发的一个大语言模型，用来生成搜索关键词；
然后通过Google Search API去网上大规模检索。API就是应用程序接口，可以理解为调用Google搜索功能的工具；
而且会优先选择维基百科这种高质量的来源。维基百科是大家公认比较权威的知识来源。
这样做的好处是什么呢？就是能克服静态语料库的覆盖局限和时效问题。静态语料库就是固定不变的数据库，可能缺少最新信息或者某些领域的信息；引入更全面的外部知识，这样就能获得更准确、更新的答案。


幻灯片第10页：CRAG推理流程
CRAG的推理流程大概分五步：
第一步评估打分（给检索结果打分），第二步置信度判定（判断是可信、不可信还是模糊），第三步策略选择（选择用什么方法处理），第四步知识整合（把有用的信息组合起来），最后第五步生成输出（产生最终答案）。
举个例子，如果置信度是Correct，系统就只做内部精炼，直接从检索到的文档里提取信息；如果是Incorrect，那就触发外部搜索，去网上找更准确的信息。这种动态流程能确保生成结果的准确性。

幻灯片第11页：系统架构的可插拔性
CRAG用的是插件式设计，它的核心组件都可以替换。可插拔性就是可以像搭积木一样，把不同的组件拼在一起：
评估器E可以适配不同的领域。比如用在医学领域，可以用医学领域的评估器；
重写器W支持多种查询改写的策略。查询改写就是把用户的原始问题改写成更容易检索的格式；
生成器G可以兼容LLaMA、GPT这些主流模型。LLaMA是Meta开发的大语言模型，GPT是OpenAI开发的。
这种设计的好处是，CRAG可以很方便地集成到现有的RAG框架里，不需要重构整个架构。重构就是推倒重来的意思。


幻灯片第12页：实现细节与超参数配置
在具体实现上，CRAG有几个关键的配置。超参数就是需要人工设置的参数，不是模型自己学出来的：
知识分段的规则是：短文本就保持单段（不切分），长文本就按句子切分（一句话一句话地分开）；
评估器配置：内部精炼时Top-k设为5（只保留得分最高的5个段落），阈值是-0.5（得分低于-0.5的就认为不可信）；
外部搜索配置：优先抓取维基百科的页面（因为维基百科质量高）；
生成模型：支持LLaMA2、SelfRAG等等。LLaMA2是LLaMA的升级版，SelfRAG是另一种RAG方法。
这些参数都可以根据任务需求灵活调整。

幻灯片第13页：实验设置
为了验证CRAG到底有没有用，论文设计了一些实验：
评测数据集用了PopQA、Biography、PubHealth、ARC-Challenge这几个。数据集就是用来测试的题目集合，PopQA是常识问答，Biography是人物传记，PubHealth是公共卫生，ARC-Challenge是科学推理；
对比的基线包括Standard RAG、Self-RAG、SAIL等等。基线就是用来对比的现有方法，Standard RAG是标准的RAG方法，Self-RAG是另一种改进的RAG方法；
评价指标主要是Accuracy、FactScore这些。Accuracy是准确率，FactScore是事实性评分，用来衡量生成内容的准确性。
实验覆盖了短文本问答、长文本生成还有推理任务这几个场景。


幻灯片第14页：实验结果：显著性能提升
实验结果显示，CRAG在多项任务上都明显比基线好：
PopQA的准确率提升了8.8%，也就是说原来100道题对80道，现在能对88道；
Biography的事实性改善了12.5%，生成的内容更准确了；
ARC的推理能力增强了7.2%，逻辑推理更好了。
另外，论文还做了Self-CRAG，就是CRAG加上Self-RAG，性能进一步提升，这说明这个方法确实有很强的可扩展性。可扩展性就是可以和其他方法组合使用，效果会更好。


幻灯片第15页：跨模型鲁棒性验证
论文在LLaMA2、SelfRAG、Alpaca、ChatGPT这些不同的模型上都测试了CRAG。LLaMA2是Meta开发的，SelfRAG是另一种方法，Alpaca是斯坦福开发的，ChatGPT是OpenAI的。结果发现，所有模型都显示出一致的性能改进，这说明CRAG确实很通用。通用性就是不管用什么模型，都能用CRAG来提升效果。这个特性让它能适用于不同规模和架构的语言模型。


幻灯片第16页：消融实验分析
论文还做了消融实验来验证各个组件的贡献。消融实验就是去掉某个组件，看看效果会怎样，这样可以知道每个组件到底有多重要：
如果移除评估器，性能会下降15%，说明评估器很重要；
如果去掉知识精炼机制，准确率会损失22%，说明知识精炼很关键；
如果禁用Web搜索，性能会降低18%，说明外部搜索也很有用。
这些结果证明了三级置信度判断策略确实有效，而且各个组件都是缺一不可的。缺一不可就是每个都很重要，不能少。


幻灯片第17页：方法优势
CRAG的核心优势可以总结为四点：
第一是插件式设计：部署很灵活，能兼容多种模型。部署就是把系统实际运行起来，灵活就是容易安装和使用；
第二是鲁棒性提升：能主动补救检索错误。主动补救就是当发现检索结果不好时，会自动去找更好的信息，而不是直接生成错误答案；
第三是噪声过滤：通过精炼机制减少无关信息的干扰。噪声就是那些不相关、会误导模型的信息；
第四是事实准确性：显著降低了幻觉现象。幻觉就是模型生成看似合理但实际错误的内容。
这些优势让CRAG能在生产环境中作为一个可靠的解决方案。生产环境就是实际应用的环境，不是实验室测试。


幻灯片第18页：局限性与挑战
虽然CRAG表现不错，但还是面临三个方面的挑战：
第一个是计算开销：额外的评估和搜索会增加延迟。延迟就是响应时间，可能需要等更久才能得到答案；
第二个是评估器质量：需要依赖高质量的标注数据。标注数据就是人工标注的正确数据，用来训练评估器，这个成本比较高；
第三个是外部依赖：Web搜索会受到网络和API的限制。如果网络不好或者API服务出问题，外部搜索就用不了。
论文提出未来可以通过模型蒸馏、缓存优化这些技术来解决这些问题。模型蒸馏就是用大模型训练小模型，让它又快又准；缓存优化就是把常用的结果存起来，下次直接用。


幻灯片第19页：未来研究方向
论文提出了四个未来的研究方向：
第一个是评估器优化：探索用自监督训练来降低对标注数据的依赖。自监督训练就是不需要人工标注，模型自己从数据中学习；
第二个是连续决策机制：扩展到更细粒度的策略空间。现在只有三种策略（可信、不可信、模糊），未来可以有很多种不同程度的策略；
第三个是方法融合：结合链式思考、工具调用这些技术。链式思考就是一步步推理，工具调用就是可以调用其他工具来帮助完成任务；
第四个是在线学习：引入用户反馈来构建闭环系统。在线学习就是系统在实际使用中不断改进，闭环系统就是用户反馈后系统自动调整。
这些方向会进一步推动CRAG的发展。


幻灯片第20页：核心贡献总结
最后，CRAG的核心贡献可以总结为：
通过检索评估、置信度判断、知识精炼和外部搜索这四大机制，显著提升了RAG的鲁棒性和事实准确性。鲁棒性就是系统在遇到问题时仍然能正常工作，事实准确性就是生成的内容更准确；
插件化设计让它能扩展到不同的模型和任务。插件化就是可以像装APP一样方便地使用；
为生产环境中降低LLM的幻觉风险提供了一个可行的路径。幻觉风险就是模型生成错误信息的可能性，CRAG提供了一个实际可行的解决方案。
谢谢大家！欢迎大家提问和讨论。
